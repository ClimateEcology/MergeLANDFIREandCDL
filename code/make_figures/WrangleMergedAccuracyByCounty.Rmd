---
title: "Calculate Accuracy of Merged CDL/NVC Raster"
author: "Melanie Kammerer"
date: "2/15/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

## Objective
The goal of this script is to map the accuracy of CDL & NVC combined rasters. To do this, I use class-level data on spatial accuracy from USDA NASS and LANDFIRE for CDL and NVC, respectively. I combined accuracy statistics from two layers by calculating an area-weighted mean.

I start by loading accuracy data for EVT and NVC. We need NVC and EVT because NVC borrows some classes from EVT and LANDFIRE does not publish accuracy values for EVT classes in NVC data files. In this section I also create a list of LANDFIRE 'managed classes' (agriculture, burned, logged, etc). These classes were not included in reference database nor accuracy assessment so, when calculating data coverage, I exclude area assigned to these classes.

```{r loadtabulardata, echo=F}
library(dplyr); library(logger); library(future); library(terra)
rm(list=ls())

# custom max function that returns NA if both input values are NA
mymax <- function(...,def=NA,na.rm=FALSE) {
    if(!is.infinite(x<-suppressWarnings(max(...,na.rm=na.rm)))) {
      x } else {def}
}

CDLYear <- 2021

# specify classes that COULD have plots in auto-key (are non-managed, not agriculture or NLCD developed)
nvc_agclasses <- c(7960:7999) # classes in LANDFIRE NVC that are agriculture

lf <- read.csv('./data/NVC_Accuracy_allregions_cleaned.csv')

nvc_classes <- read.csv('./data/TabularData/LF_200NVC_05142020.csv')

managed_classes <- nvc_classes$VALUE[grepl(nvc_classes$NVC_Name, pattern='Developed-') | 
                                       grepl(nvc_classes$NVC_Name, pattern='Recently Burned-') | 
                                       grepl(nvc_classes$NVC_Name, pattern='Recently Logged-') | 
                                       grepl(nvc_classes$NVC_Name, pattern='Recently Disturbed Other-') | 
                                       grepl(nvc_classes$NVC_Name, pattern='Forest Plantation') | 
                                       nvc_classes$VALUE %in% nvc_agclasses |
                                         nvc_classes$NVC_Name == 'Open Water']
```
 
## Load NVC pixel frequency by county
Here, I load datasets generated by 'TabulatePixels3Rasters.R' script. All LANDFIRE accuracy assessments were conducted by region, so I also need to load a shapefile of the LF regions and label each county with the region it is contained within. Some counties cross regional boundaries, so I determine the appropriate region based on the centroid of each county polygons (some counties have multiple polygons due to non-contiguous land).
```{r loadfreq, echo=F}
library(dplyr)
# read county shapefile with LANDFIRE regions
county <- sf::st_read('./data/SpatialData/us_counties_better_coasts_LFregion.shp') %>%
  dplyr::rename(LF2010_Region=LF2010_) # fix column name that was abbreviated by shp driver

# read NVC/CDL pixel frequency data
merged_freq <- read.csv(paste0('./data/PixelFreq/CDL', CDLYear, 'NVC_CountyPixelFreq.csv')) %>%
  dplyr::filter(!is.na(County)) %>%
  dplyr::group_by(State, County) %>%
  dplyr::mutate(PctCounty = (NCells/sum(NCells)) *100) %>%
  dplyr::ungroup()

# are there any counties in county shapefile that are NOT in dataset on NVC pixel frequency?
paste0(county$COUNTY, ", ", county$STATE)[!paste0(county$COUNTY, ", ", county$STATE) %in% paste0(merged_freq$County, ", ", merged_freq$State)]

# join pixel frequency with LF regions
merged_freq_sf <- county %>%
    dplyr::select(FIPS, STATE, COUNTY, LF2010_Region) %>%
    dplyr::left_join(merged_freq, by=c('STATE'='State', 'COUNTY'='County'))

# join pixel frequency with LF regions
merged_freq <- sf::st_drop_geometry(county) %>%
    dplyr::select(STATE, COUNTY, LF2010_Region) %>%
    dplyr::left_join(merged_freq, by=c('STATE'='State', 'COUNTY'='County'))

```
```{r plot_nodata, fig.width=10, fig.height=6}

# fill in a few missing polygons that show up on no data map
counties <- sf::st_read('./data/SpatialData/us_counties_better_coasts.shp') %>%
  dplyr::filter(!is.na(COUNTY))

nodata_freq <- merged_freq_sf %>%
  sf::st_drop_geometry() %>%
  dplyr::filter(Class == -1001)

nodata <- counties %>%
  dplyr::select(FIPS, STATE, COUNTY) %>%
  dplyr::left_join(nodata_freq) %>%
  tidyr::replace_na(list(PctCounty=0))

sf::st_drop_geometry(nodata) %>%
write.csv('./data/TechnicalValidation/FinalRaster_FreqPixelsUnresolvedConflict.csv')

sf::st_write(nodata, './data/TechnicalValidation/FinalRaster_FreqPixelsUnresolvedConflict.shp', delete_dsn=T)


library(ggplot2); library(viridis)
# calculate jenk's breaks to use on map
natural.interval.nodata <- BAMMtools::getJenksBreaks(nodata$PctCounty, k = 7)
nodata$PctCounty.jenks = cut(nodata$PctCounty, breaks=natural.interval.nodata , include.lowest = TRUE)

# map producer accuracy of NVC by county
nodata_map_jenks <- ggplot() + geom_sf(data=nodata, aes(fill=PctCounty.jenks),  color=NA) +  
  guides(fill=guide_legend(title='Percent county\nunresolved pixels')) +
  theme_classic(base_size=13) +
  scale_fill_viridis(discrete=T, option='inferno') +
  theme(legend.position=c(0.925,0.27),
        strip.text.x = element_text(size = 14),
        strip.text.y = element_text(size = 14))

nodata_map_jenks

saveRDS(nodata_map_jenks, paste0('./data/nodata_map_jenks_CDL', CDLYear, '.rds'))

```

## Join NVC accuracy metrics with pixel frequency
```{r joinnvc}
# join accuracy values to pixel frequency data
nvc_accuracy <- dplyr::left_join(merged_freq, dplyr::select(nvc_classes, VALUE, NVC_Name), by=c('Class'= 'VALUE')) %>%
  dplyr::distinct() %>%
  dplyr::left_join(dplyr::select(lf, -LANDFIRE_NVC, -LANDFIRE_Name, -LANDFIRE_EVT), 
                   by=c('Class'='LANDFIRE_Class', 'LF2010_Region'='Region')) %>%
  dplyr::select(-contains('.evt') , -contains('.nvc'))

# why are there some counties with NA for NVC value?
nvc_accuracy[is.na(nvc_accuracy$Class),]

# make new variable of reference database status (well-represented, poorly-represented, absent, or managed/ag)
nvc_accuracy$RFDB_Status <- if_else(nvc_accuracy$Class %in% managed_classes, 'absent, managed/ag/disturbed', 
                            if_else((nvc_accuracy$ProducerNPlots_autokey == 0|is.na(nvc_accuracy$ProducerNPlots_autokey)) & 
                                 !nvc_accuracy$Class %in% managed_classes,  'absent, could be added', 
                            if_else(nvc_accuracy$ProducerNPlots_autokey >= 30, 'well-represented',
                            if_else(nvc_accuracy$ProducerNPlots_autokey < 30 & nvc_accuracy$ProducerNPlots_autokey > 0, 'poorly-represented',
                                  'not NVC'))))

```

## Join CDL accuracy metrics with pixel frequency
```{r joincdl}
cdl <- read.csv('./data/CDL_Accuracy/CDL_accuracy_long_allstates_2012to2020.csv')  %>%
  dplyr::mutate(GT_Status = if_else(is.na(Producer), "no ground-truth", "present")) %>%
  dplyr::rename(ProducerAccuracy=Producer, UserAccuracy=User) %>%
  dplyr::mutate(CDL_Class = -CDL_Class)

# filter cdl to 2016 to match pixel freq data
cdl_oneyear <- dplyr::filter(cdl, Year %in% CDLYear)

#cdl_freq <- read.csv(paste0('./data/PixelFreq/CDL', CDLYear, '_CountyPixelFreq.csv'))

head(cdl_oneyear)
combined_accuracy <- dplyr::left_join(nvc_accuracy, cdl_oneyear,  by=c('Class'='CDL_Class', 
                                                                  'STATE'='State'), suffix=c('.nvc', '.cdl')) 
```


## Calculate area-weighted version of accuracy
```{r areaweight}
# calculate total number of cells per county as well as accuracy*NCells of a specific class (will sum in next step to get area-weighted average)
combined_accuracy2 <- dplyr::group_by(combined_accuracy, STATE, COUNTY, Class) %>%
  dplyr::mutate(ProducerAccuracy=mymax(ProducerAccuracy.nvc, ProducerAccuracy.cdl, na.rm=T),
                                   UserAccuracy=mymax(UserAccuracy.nvc, UserAccuracy.cdl, na.rm=T), # select source of accuracy value
                                   ClassStatusLong= if_else(is.na(CDL_Name), paste0('nvc: ', RFDB_Status), paste0('cdl: ',GT_Status)),
                ClassStatusShort = if_else(ClassStatusLong %in% c('cdl: present', 'nvc: well-represented'), 'well-represented',
                                   if_else(ClassStatusLong %in% c('nvc: poorly-represented'), 'poorly-represented', 'absent')),
                DataSource= if_else(grepl(ClassStatusLong, pattern='nvc: '), 'NVC',
                                   if_else(grepl(ClassStatusLong, pattern='cdl: '), 'CDL', 'uh-oh'))) %>% 
  dplyr::ungroup() %>%
  dplyr::group_by(STATE, COUNTY) %>%
  dplyr::mutate(NCells_County= sum(NCells), 
                Weight_ProdAcc = NCells*ProducerAccuracy,
                Weight_UserAcc = NCells*UserAccuracy,
                NCells_CDL = sum(NCells[DataSource == 'CDL']),
                NCells_NVC = sum(NCells[DataSource == 'NVC'])) 


# summarize ncell and accuracy by county and reference db status
# accuracy only applies to well-represented, but we will map data coverage of well and poorly represented classes
combined_accuracy_bycounty <-  combined_accuracy2  %>%
  dplyr::group_by(STATE, COUNTY, NCells_CDL, NCells_NVC, NCells_County, ClassStatusShort) %>%
  dplyr::summarize(NCells_Group = sum(NCells, na.rm=T), 
    Weight_ProdAcc = sum(Weight_ProdAcc, na.rm=T)/NCells_Group,
    Weight_UserAcc = sum(Weight_UserAcc, na.rm=T)/NCells_Group, .groups='keep') %>%
  dplyr::mutate(ClassStatusShort2=ClassStatusShort) %>%
  dplyr::ungroup()

# reshape ncells to wide format
ncells <- tidyr::pivot_wider(combined_accuracy_bycounty, id_cols=c(STATE:COUNTY, NCells_CDL, NCells_NVC, NCells_County),   names_from=ClassStatusShort, values_from=NCells_Group) %>%
  tidyr::replace_na(list(`well-represented` = 0, `poorly-represented` = 0))
  
# reshape accuracy to wide format, filter to only well-represented classes
acc <- dplyr::filter(combined_accuracy_bycounty, ClassStatusShort == 'well-represented') %>% 
  tidyr::pivot_wider(id_cols=c(STATE:COUNTY, NCells_CDL, NCells_NVC, NCells_County), names_from=ClassStatusShort, 
                     values_from=c(Weight_ProdAcc, Weight_UserAcc)) %>%
  dplyr::rename(WtdUserAcc = `Weight_UserAcc_well-represented`, WtdProdAcc = `Weight_ProdAcc_well-represented`)

# translate ncells to percentage of county area
toplot <- dplyr::mutate(ncells, PropCDL = NCells_CDL/NCells_County,
                        Rep_PctCounty = ((`well-represented` + `poorly-represented`)/NCells_County)*100,
                        WellRep_PctCounty = ((`well-represented`)/NCells_County)*100)
```

## Write data files for combined data coverage and accuracy 
```{r datacoverage_maps}
library(classInt); library(ggplot2); library(viridis)

# join results to spatial object for mapping
toplot_sf <- dplyr::left_join(county, toplot) %>%
  dplyr::left_join(acc)

sf::st_drop_geometry(toplot_sf) %>%
write.csv(paste0('./data/MergedAccuracy_', CDLYear, ".csv"), row.names = F)
```

